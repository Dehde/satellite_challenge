{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import shuffle\n",
    "import time\n",
    "\n",
    "\n",
    "direct = 'all_bandsCuts100/all_cuts/'\n",
    "files = os.listdir(direct)\n",
    "#files = files[0:1000]\n",
    "all_labels = []\n",
    "all_images = []\n",
    "print('loading files...')\n",
    "for file in files:\n",
    "    temp = np.load(direct+file)\n",
    "    all_images += [temp['arr_0']]\n",
    "    all_labels += [temp['arr_1']]\n",
    "    \n",
    "\n",
    "#rescaling everything to 0..1\n",
    "all_images=np.array(all_images, dtype=np.float32)\n",
    "all_labels=np.array(all_labels, dtype=np.float32)\n",
    "\n",
    "print \"image shape: \", all_images.shape\n",
    "imageShape = all_images.shape[1:]\n",
    "\n",
    "N_channels = len(all_images[0,0,0,:])\n",
    "maximu = np.zeros(N_channels)\n",
    "minimu = np.zeros(N_channels)\n",
    "for i in range(N_channels):\n",
    "    maximu[i] = np.max(all_images[:,:,:,i])\n",
    "    minimu[i] = np.min(all_images[:,:,:,i])\n",
    "    all_images[:,:,:,i] = (all_images[:,:,:,i]-minimu[i])/(maximu[i]-minimu[i])\n",
    "\n",
    "print('...files loaded')\n",
    "\"\"\"\n",
    "def make_clts_data(size=1, imageShape = (83,83,8)):\n",
    "    indices = np.random.randint(all_images.shape[0],size=size)\n",
    "    ims = np.zeros([size,83,83,8])\n",
    "    labs = np.zeros([size,83,83,10]) \n",
    "    for j in range(len(indices)):\n",
    "        ims[j,:,:,:] = all_images[indices[j],:,:,:]\n",
    "        labs[j,:,:,:] = all_labels[indices[j],:,:,:]\n",
    "    return ims, labs\n",
    "\"\"\"\n",
    "def make_clts_data(size=1):\n",
    "    indices = np.random.randint(all_images.shape[0],size=size)\n",
    "    rotate = np.random.randint(4)\n",
    "    flip = np.random.randint(1)\n",
    "    ims = np.zeros([size,83,83,16])\n",
    "    labs = np.zeros([size,83,83,10])\n",
    "    for j in range(len(indices)):\n",
    "        ims[j,:,:,:] = all_images[indices[j],:,:,:]\n",
    "        labs[j,:,:,:] = all_labels[indices[j],:,:,:]\n",
    "    ims = np.rot90(ims,k=rotate,axes=(1,2))\n",
    "    labs = np.rot90(labs,k=rotate,axes=(1,2))\n",
    "    if flip == 1:\n",
    "        ims=np.fliplr(ims)\n",
    "        labs=np.fliplr(labs)\n",
    "    return ims, labs\n",
    "\n",
    "def make_clts_test(size=100):\n",
    "    ims = np.zeros([size,83,83,16])\n",
    "    labs = np.zeros([size,83,83,10])\n",
    "    ims = all_images[0:size,:,:,:]\n",
    "    labs= all_labels[0:size,:,:,:]\n",
    "    return ims, labs\n",
    "\n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.6)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(-0.1, shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "# factor that controls how much alpha nd beta are updated\n",
    "memory_factor = 0.999  \n",
    "\n",
    "def Jacc(activations, truth):\n",
    "    TPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*(1-truth),axis = 0),axis=0),axis=0)\n",
    "    FNc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum((1-activations)*truth,axis = 0),axis=0),axis=0)\n",
    "    return tf.reduce_mean((TPc + 0.01) / (TPc + FPc + FNc + 2.))\n",
    "\n",
    "def individualJacc(activations, truth):\n",
    "    TPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*(1-truth),axis = 0),axis=0),axis=0)\n",
    "    FNc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum((1-activations)*truth,axis = 0),axis=0),axis=0)\n",
    "    return (TPc  + 0.01) / (TPc + FPc + FNc  + 2.)\n",
    "\n",
    "def alphbet_np(activations, truth):\n",
    "    global alpha\n",
    "    global beta\n",
    "\n",
    "    TPc = np.sum(np.sum(np.sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FNc = np.sum(np.sum(np.sum((1-activations)*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = np.sum(np.sum(np.sum(activations*(1.-truth),axis=0),axis=0),axis=0)\n",
    "    alpha = memory_factor*alpha + TPc*(1.-memory_factor)\n",
    "    beta = memory_factor*beta + (TPc+FNc+FPc)*(1.-memory_factor)\n",
    "    \n",
    "def conv2d(xt,Wt):\n",
    "    return tf.nn.conv2d(xt,Wt,strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, None,None,16])\n",
    "    x_image = x\n",
    "\n",
    "    N_hidden = 60\n",
    "    N_hidden3 = 100\n",
    "    N_feature = 10\n",
    "    filtSize = 17\n",
    "    filtSize2 = 1\n",
    "    \"\"\"\n",
    "    W_conv1 = weight_variable([filtSize,filtSize,16,N_hidden],name='W_conv1')\n",
    "    b_conv1 = bias_variable([N_hidden],name='b_conv1')\n",
    "    conv_1 = tf.nn.sigmoid(conv2d(x_image, W_conv1)+b_conv1)\n",
    "    #conv_1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "\n",
    "    W_conv2 = weight_variable([1,1,N_hidden,N_feature], name='W_conv2')\n",
    "    b_conv2 = bias_variable([N_feature],name='b_conv2')\n",
    "    conv_2 = tf.nn.sigmoid(conv2d(conv_1,W_conv2)+b_conv2)\n",
    "    y_conv = conv_2\n",
    "    \"\"\"\n",
    "    W_conv1 = weight_variable([filtSize,filtSize,16,N_hidden3],name='W_conv1')\n",
    "    b_conv1 = bias_variable([N_hidden3],name='b_conv1')\n",
    "    conv_1 = tf.nn.sigmoid(conv2d(x_image, W_conv1)+b_conv1)\n",
    "    #conv_1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "\n",
    "    W_conv3 = weight_variable([filtSize2,filtSize2,N_hidden3,N_hidden],name='W_conv3')\n",
    "    b_conv3 = bias_variable([N_hidden],name='b_conv3')\n",
    "    conv_3 = tf.nn.sigmoid(conv2d(conv_1, W_conv3)+b_conv3)\n",
    "\n",
    "    W_conv2 = weight_variable([1,1,N_hidden,N_feature], name='W_conv2')\n",
    "    b_conv2 = bias_variable([N_feature],name='b_conv2')\n",
    "    conv_2 = tf.nn.sigmoid(conv2d(conv_3,W_conv2)+b_conv2)\n",
    "    y_conv = conv_2\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    y_truth = tf.placeholder(tf.float32, [None, None, None, N_feature])\n",
    "\n",
    "alph = tf.placeholder(tf.float32, [10])\n",
    "bet = tf.placeholder(tf.float32, [10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y_truth, logits = y_conv))\n",
    "jacc_loss = -Jacc(y_conv, y_truth, alph, bet)\n",
    "jacc_loss_reg = jacc_loss + 0.5e-5*tf.reduce_mean(W_conv1*W_conv1) + 0.5e-5*tf.reduce_mean(W_conv2*W_conv2)\n",
    "indiv_jacc = individualJacc(y_conv,y_truth)\n",
    "\n",
    "learningRate = tf.placeholder(tf.float32, shape=[])\n",
    "train_step = tf.train.AdamOptimizer(learningRate).minimize(jacc_loss_reg)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.reduce_sum(tf.round(y_truth)*tf.round(y_conv),axis=3)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "#saver.restore(sess, \"/tmp/model2.ckpt\")\n",
    "Learn = 0.001\n",
    "start = time.time()\n",
    "\n",
    "for i in range(100000):\n",
    "    images, labels = make_clts_data(10)\n",
    "    train_step.run(feed_dict={x:images, y_truth:labels, learningRate: Learn})\n",
    "    \n",
    "    if i == 70000:\n",
    "        Learn = 0.0001\n",
    "    \n",
    "    if 0 == (i%10):\n",
    "        print('step', i)\n",
    "        testimages, testlabels = make_clts_test()\n",
    "        predict = y_conv.eval(feed_dict={x: testimages, y_truth:testlabels})\n",
    "        print('JACCloss TestSet:',jacc_loss.eval(feed_dict={x:testimages, y_truth:testlabels}))\n",
    "        print('individual JACC',indiv_jacc.eval(feed_dict={x: testimages, y_truth: testlabels}))\n",
    "        \n",
    "        print \"500 steps took\", (time.time()-start)/60\n",
    "        start = time.time()\n",
    "testimages, testlabels = make_clts_test()        \n",
    "final_loss = jacc_loss.eval(feed_dict={x: testimages, y_truth: testlabels})\n",
    "print('final JACCloss:',final_loss)\n",
    "\n",
    "\n",
    "save_path = saver.save(sess, \"NNET_checkpoint/bmodelr{}.ckpt\".format(\"DeepNNet_subm\"))\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Learn = 0.0001\n",
    "for i in range(1000):\n",
    "    images, labels = make_clts_data(10)\n",
    "    alpha = np.zeros(10)\n",
    "    beta = np.zeros(10)\n",
    "    train_step.run(feed_dict={x:images, y_truth:labels, learningRate: Learn})\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 0 == (i%500):\n",
    "        print('step', i)\n",
    "        testimages, testlabels = make_clts_test()\n",
    "        predict = y_conv.eval(feed_dict={x: testimages, y_truth:testlabels})\n",
    "        print('JACCloss TestSet:',jacc_loss.eval(feed_dict={x:testimages, y_truth:testlabels}))\n",
    "        print('individual JACC',indiv_jacc.eval(feed_dict={x: testimages, y_truth: testlabels}))\n",
    "        \n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from collections import defaultdict\n",
    "import tifffile as tiff\n",
    "\n",
    "def show_mask(m):\n",
    "    tiff.imshow(255 * np.stack([m, m, m]));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot\n",
    "import cv2\n",
    "print \"started\"\n",
    "\n",
    "\n",
    "\n",
    "submIM_IDs = []\n",
    "cur_dir = '/home/rob/Udacity/capstone/data'\n",
    "with open(cur_dir + '/sample_submission.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            i = 1\n",
    "        if (i%10) == 0:\n",
    "            submIM_IDs.append(row[0])        \n",
    "\n",
    "trainIM_IDs = []\n",
    "with open(cur_dir + '/train_wkt_v4.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            i = 1\n",
    "        if (i%10) == 0:\n",
    "            trainIM_IDs.append(row[0])\n",
    "#submIM_IDs = trainIM_IDs\n",
    "\n",
    "N_channels = 16\n",
    "    \n",
    "def make_subm_data(size, iteration):\n",
    "    # Maske hier laden aus Bild und normieren\n",
    "    \n",
    "    IM_ID = submIM_IDs[iteration]\n",
    "    \n",
    "    im = tiff.imread(cur_dir +'/sixteen_band/{}_A.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    resized_image_A = cv2.resize(im, (832, 834), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    im = tiff.imread(cur_dir +'/sixteen_band/{}_M.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    resized_image_M = cv2.resize(im, (832, 834), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    ims_size = resized_image_M.shape[:2]\n",
    "    \n",
    "    image = np.empty((1,834,832,16),dtype=np.float32)\n",
    "    image[0,:,:,:8] = resized_image_M[:,:,:]\n",
    "    image[0,:,:,8:16] = resized_image_A[:,:,:] \n",
    "    for i in range(N_channels):\n",
    "        image[0,:,:,i] = (image[0,:,:,i]-minimu[i])/(maximu[i]-minimu[i])\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(submIM_IDs)):\n",
    "    if i%10 == 0:\n",
    "        print \"picture number: \", str(i)\n",
    "    IM_ID = submIM_IDs[i]\n",
    "    images = make_subm_data(size=1, iteration=i)\n",
    "    imageShape = images.shape[1:]\n",
    "    \n",
    "    prediction_mask = y_conv.eval(feed_dict={x: images})\n",
    "    \n",
    "    np.savez('prediction_masks_16band_031NET/pred{}'.format(IM_ID), prediction_mask)\n",
    "    \n",
    "\n",
    "print \"job done.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
