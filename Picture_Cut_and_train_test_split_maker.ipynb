{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import cv2\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import time\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "import math\n",
    "from PIL import Image\n",
    "csv.field_size_limit(sys.maxsize);\n",
    "cur_dir = '/home/rob/Udacity/capstone/data'\n",
    "\n",
    "ClassNames = {'1':'buildings', '2':'Misc. Manmade structures', '3': 'Road', '4':'Track', '5':'Trees',\n",
    "                    '6':'Crops', '7':'Waterway', '8':'Standing water', '9':'Vehicle Large ', '10':'Vehicle Small'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "train_masks = {}\n",
    "pred_masks = {}\n",
    "\n",
    "trainIM_IDs = []\n",
    "with open(cur_dir + '/train_wkt_v4.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            i = 1\n",
    "        if (i%10) == 0:\n",
    "            trainIM_IDs.append(row[0])\n",
    "\n",
    "testIM_IDs = []\n",
    "with open(cur_dir + '/sample_submission.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar=',')\n",
    "    for i,row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            i = 1\n",
    "        if (i%10) == 0:\n",
    "            testIM_IDs.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_scalers(im_size):\n",
    "    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n",
    "    h, w = float(h), float(w)\n",
    "    w_ = w * (w / (w + 1))\n",
    "    h_ = h * (h / (h + 1))\n",
    "    return w_ / x_max, h_ / y_min\n",
    "\n",
    "def mask_for_polygons(polygons):\n",
    "    img_mask = np.zeros(im_size, np.uint8)\n",
    "    if not polygons:\n",
    "        return img_mask\n",
    "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n",
    "    interiors = [int_coords(pi.coords) for poly in polygons\n",
    "                 for pi in poly.interiors]\n",
    "    cv2.fillPoly(img_mask, exteriors, 1)\n",
    "    cv2.fillPoly(img_mask, interiors, 0)\n",
    "    return img_mask\n",
    "    \n",
    "def mask_to_polygons(mask, epsilon=10., min_area=10.):\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    image, contours, hierarchy = cv2.findContours(\n",
    "        ((mask == 1) * 255).astype(np.uint8),\n",
    "        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    # create approximate contours to have reasonable submission size\n",
    "    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n",
    "                       for cnt in contours]\n",
    "    if not contours:\n",
    "        return MultiPolygon()\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(approx_contours[idx])\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "    for idx, cnt in enumerate(approx_contours):\n",
    "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
    "            assert cnt.shape[1] == 1\n",
    "            poly = Polygon(\n",
    "                shell=cnt[:, 0, :],\n",
    "                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n",
    "                       if cv2.contourArea(c) >= min_area])\n",
    "            all_polygons.append(poly)\n",
    "    # approximating polygons might have created invalid ones, fix them\n",
    "    all_polygons = MultiPolygon(all_polygons)\n",
    "    if not all_polygons.is_valid:\n",
    "        all_polygons = all_polygons.buffer(0)\n",
    "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
    "        # need to keep it a Multi throughout\n",
    "        if all_polygons.type == 'Polygon':\n",
    "            all_polygons = MultiPolygon([all_polygons])\n",
    "    return all_polygons\n",
    "\n",
    "def pieceCutter(im_size, cuts, IM_ID, image, trainMasks):\n",
    "    x_cutter = math.floor(im_size[0]/cuts)\n",
    "    y_cutter = math.floor(im_size[1]/cuts)\n",
    "    A = [int(x_cutter*i) for i in range(cuts+1)]\n",
    "    B = [int(y_cutter*i) for i in range(cuts+1)]\n",
    "    \n",
    "    for x in range(cuts):\n",
    "        for y in range(cuts):\n",
    "            print \"in loop\", x, y, \"report_visualization/{}-{}-{}\".format(IM_ID,x,y)\n",
    "            cutPicture = im[A[x]:A[x+1],B[y]:B[y+1],:]\n",
    "            print cutPicture.shape\n",
    "            cutMasks = trainMasks[A[x]:A[x+1],B[y]:B[y+1],:]\n",
    "            print cutMasks.shape\n",
    "            np.savez_compressed(\"report_visualization/{}-{}-{}\".format(IM_ID,x,y), cutPicture, cutMasks)\n",
    "            \n",
    "def sizeNormalizer(minsize,im,trainMasks):\n",
    "    image_out = im[:minsize[0],:minsize[1],:]\n",
    "    mask_out = trainMasks[:minsize[0],:minsize[1],:]\n",
    "    return image_out, mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "6040_2_2\n",
      "in loop 0 0 report_visualization/6040_2_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6120_2_2\n",
      "in loop 0 0 report_visualization/6120_2_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6120_2_0\n",
      "in loop 0 0 report_visualization/6120_2_0-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6090_2_0\n",
      "in loop 0 0 report_visualization/6090_2_0-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6040_1_3\n",
      "in loop 0 0 report_visualization/6040_1_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6040_1_0\n",
      "in loop 0 0 report_visualization/6040_1_0-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6100_1_3\n",
      "in loop 0 0 report_visualization/6100_1_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6010_4_2\n",
      "in loop 0 0 report_visualization/6010_4_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6110_4_0\n",
      "in loop 0 0 report_visualization/6110_4_0-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6140_3_1\n",
      "in loop 0 0 report_visualization/6140_3_1-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6110_1_2\n",
      "in loop 0 0 report_visualization/6110_1_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6100_2_3\n",
      "in loop 0 0 report_visualization/6100_2_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6150_2_3\n",
      "in loop 0 0 report_visualization/6150_2_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6160_2_1\n",
      "in loop 0 0 report_visualization/6160_2_1-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6140_1_2\n",
      "in loop 0 0 report_visualization/6140_1_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6110_3_1\n",
      "in loop 0 0 report_visualization/6110_3_1-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6010_4_4\n",
      "in loop 0 0 report_visualization/6010_4_4-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6170_2_4\n",
      "in loop 0 0 report_visualization/6170_2_4-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6170_4_1\n",
      "in loop 0 0 report_visualization/6170_4_1-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6170_0_4\n",
      "in loop 0 0 report_visualization/6170_0_4-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6060_2_3\n",
      "in loop 0 0 report_visualization/6060_2_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6070_2_3\n",
      "in loop 0 0 report_visualization/6070_2_3-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6010_1_2\n",
      "in loop 0 0 report_visualization/6010_1_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6040_4_4\n",
      "in loop 0 0 report_visualization/6040_4_4-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "6100_2_2\n",
      "in loop 0 0 report_visualization/6100_2_2-0-0\n",
      "(834, 832, 16)\n",
      "(834, 832, 10)\n",
      "job done\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Cut pictures into 1 size \"\"\"\n",
    "import cv2\n",
    "\n",
    "#These values were determined in a later part of this notebook\n",
    "rgb_minsize = [3345, 3389]\n",
    "M_minsize = [834, 832]\n",
    "streets_minsize = [500,500]\n",
    "A_minsize = [133, 132]\n",
    "cars_minsize = [1700,1700]\n",
    "\n",
    "minsize = M_minsize\n",
    "nrCuts = 1\n",
    "print len(trainIM_IDs)\n",
    "\n",
    "\n",
    "for IM_ID in trainIM_IDs[:]:\n",
    "    print IM_ID\n",
    "    \"\"\"\n",
    "    im_rgb = tiff.imread(cur_dir +'/three_band/{}.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    resized_image_rgb = cv2.resize(im_rgb, (minsize[0],minsize[1]), interpolation=cv2.INTER_AREA)\n",
    "    im_size = resized_image_rgb.shape[:2]\n",
    "    \n",
    "    im = np.empty((minsize[0],minsize[1],3),dtype=np.uint16)\n",
    "    trainMasks = np.empty([im_size[0],im_size[1],10])\n",
    "    im = resized_image_rgb\n",
    "    \"\"\"\n",
    "    \n",
    "    trainMasks = np.empty([minsize[0],minsize[1],10])\n",
    "\n",
    "    \n",
    "    \n",
    "    im = tiff.imread(cur_dir +'/sixteen_band/{}_A.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    resized_image_A = cv2.resize(im, (minsize[1], minsize[0]), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    im = tiff.imread(cur_dir +'/sixteen_band/{}_M.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    resized_image_M = cv2.resize(im, (minsize[1], minsize[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    im_size = resized_image_M.shape[:2]\n",
    "    \n",
    "    im = np.empty((minsize[0], minsize[1],16),dtype=np.uint16)\n",
    "    im[:,:,:8] = resized_image_M[:,:,:]\n",
    "    im[:,:,8:16] = resized_image_A[:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    x_max = y_min = None\n",
    "    for _im_id, _x, _y in csv.reader(open(cur_dir + '/grid_sizes.csv')):\n",
    "        if _im_id == IM_ID:\n",
    "            x_max, y_min = float(_x), float(_y)\n",
    "            break\n",
    "\n",
    "    for i in range(1,11):\n",
    "        POLY_TYPE = str(i)\n",
    "\n",
    "        train_polygons = None\n",
    "        for _im_id, _poly_type, _poly in csv.reader(open(cur_dir + '/train_wkt_v4.csv')):\n",
    "            if _im_id == IM_ID and _poly_type == POLY_TYPE:\n",
    "                train_polygons = shapely.wkt.loads(_poly)\n",
    "                break\n",
    "\n",
    "        x_scaler, y_scaler = get_scalers(im_size)\n",
    "\n",
    "        train_polygons_scaled = shapely.affinity.scale(\n",
    "            train_polygons, xfact=x_scaler, yfact=y_scaler, origin=(0, 0, 0))\n",
    "\n",
    "        #train_mask = np.empty_like(im[:,:,:10])\n",
    "        train_mask = mask_for_polygons(train_polygons_scaled)\n",
    "        trainMasks[:,:,(int(i)-1)] = train_mask #trainMasks: im_size,im_size,10 classes\n",
    "\n",
    "    #train_mask = np.empty_like(im[:,:,:10])\n",
    "    pieceCutter(minsize, nrCuts, IM_ID, im, trainMasks)\n",
    "\n",
    "    \n",
    "print \"job done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Determine smallest size of pictures '''\n",
    "\n",
    "all_pics = trainIM_IDs + testIM_IDs\n",
    "\n",
    "liste = []\n",
    "counter = 0\n",
    "for IM_ID in all_pics:\n",
    "    print \"pic {}\".format(counter)\n",
    "    im = tiff.imread(cur_dir +'/sixteen_band/{}_M.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    im_size = im.shape[:2]\n",
    "    im = tiff.imread(cur_dir +'/three_band/{}.tif'.format(IM_ID)).transpose([1, 2, 0])\n",
    "    im_size = im.shape[:2]\n",
    "    liste.append(im_size)\n",
    "    counter += 1\n",
    "\n",
    "min(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6170_4_1-0-0.npz', '6100_1_3-0-0.npz', '6160_2_1-0-0.npz', '6010_1_2-0-0.npz', '6010_4_4-0-0.npz', '6090_2_0-0-0.npz', '6040_2_2-0-0.npz', '6140_1_2-0-0.npz', '6120_2_2-0-0.npz', '6170_2_4-0-0.npz', '6100_2_3-0-0.npz', '6110_3_1-0-0.npz', '6150_2_3-0-0.npz', '6140_3_1-0-0.npz', '6110_4_0-0-0.npz', '6040_4_4-0-0.npz', '6060_2_3-0-0.npz', '6170_0_4-0-0.npz', '6110_1_2-0-0.npz', '6040_1_3-0-0.npz', '6070_2_3-0-0.npz', '6120_2_0-0-0.npz', '6010_4_2-0-0.npz', '6040_1_0-0-0.npz', '6100_2_2-0-0.npz']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy\n",
    "from random import shuffle\n",
    "paths = os.listdir(\"report_visualization/\")\n",
    "print paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 5\n",
      "start loading files..\n",
      "[8, 9]\n",
      "files loaded\n",
      "all pixels: 17347200\n",
      "number of class pixels [  7.39901000e+05   2.77289000e+05   1.55024000e+05   5.46430000e+05\n",
      "   2.29509900e+06   4.83879000e+06   9.19360000e+04   3.28470000e+04\n",
      "   1.08100000e+03   6.44700000e+03]\n",
      "percentage of class-pixels per all pixels [  4.26524742e-02   1.59846546e-02   8.93654307e-03   3.14996080e-02\n",
      "   1.32303715e-01   2.78937811e-01   5.29976019e-03   1.89350443e-03\n",
      "   6.23155322e-05   3.71644992e-04]\n"
     ]
    }
   ],
   "source": [
    "train_split = paths[:]\n",
    "test_split = paths[20:]\n",
    "print len(train_split), len(test_split)\n",
    "\n",
    "masks1 = []\n",
    "masks2 = []\n",
    "print \"start loading files..\"\n",
    "print range(8,10)\n",
    "for path in train_split:\n",
    "    data = numpy.load(\"report_visualization/\"+path)\n",
    "    masks1.append(data['arr_1'])\n",
    "    \n",
    "for path in test_split:\n",
    "    data = numpy.load(\"report_visualization/\"+path)\n",
    "    masks2.append(data['arr_1'])\n",
    "print \"files loaded\" \n",
    "mean = numpy.empty(10)\n",
    "num = numpy.empty(10)\n",
    "mean2 = numpy.empty(10)\n",
    "num2 = numpy.empty(10)\n",
    "\n",
    "for i in range(0,10):\n",
    "    n_class_train = [sum(sum(mask[:,:,i])) for mask in masks1]\n",
    "    n_class_test = [sum(sum(mask[:,:,i])) for mask in masks2]\n",
    "    [num[i], mean[i]]=[sum(n_class_train),numpy.mean(n_class_train)]\n",
    "    [num2[i], mean2[i]]=[sum(n_class_test),numpy.mean(n_class_test)]\n",
    "    \n",
    "all_pixels = minsize[0]*minsize[1]*25\n",
    "\n",
    "print \"all pixels:\", all_pixels\n",
    "print \"number of class pixels\", num\n",
    "print \"percentage of class-pixels per all pixels\", num/all_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_train_split = train_split\n",
    "final_test_split = test_split\n",
    "\n",
    "\n",
    "masks = []\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "for path in final_train_split:\n",
    "    data = numpy.load(\"all_bandsCuts100/\"+path)\n",
    "    mask = data['arr_1']\n",
    "    images = data['arr_0']\n",
    "    np.savez_compressed(\"train_cuts/{}\".format(path[:-4]), images, mask)\n",
    "    \n",
    "    print counter\n",
    "    counter += 1\n",
    "\n",
    "masks = []\n",
    "images = []\n",
    "\n",
    "\n",
    "for path in final_test_split:\n",
    "    data = numpy.load(\"all_bandsCuts100/\"+path)\n",
    "    mask = data['arr_1']\n",
    "    images = data['arr_0']\n",
    "    np.savez_compressed(\"test_cuts/{}\".format(path[:-4]), images, mask)\n",
    "    \n",
    "    print counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
