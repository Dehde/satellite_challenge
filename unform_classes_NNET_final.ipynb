{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################### DATA WRAPPER ##########################################\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# rounds x up or down such that the expectation value of x is preserved\n",
    "def rand_round(x):\n",
    "\twhole = int(x)\n",
    "\tr = np.random.random()\n",
    "\tif r < x-whole:\n",
    "\t\twhole += 1\n",
    "\treturn whole\n",
    "\t\n",
    "#gives a rotated and mirrored version of d\n",
    "def augment_data(d,i):\n",
    "\trot = i//2\n",
    "\tflip = i % 2\n",
    "\tif flip == 0:\n",
    "\t\td = np.fliplr(d)\n",
    "\treturn np.rot90(d,rot)\n",
    "\t\n",
    "#primitive data wrapper to be extended\n",
    "class DataWrapper:\n",
    "\tdef __init__(self, stichSize):\n",
    "\t\tprint('loading files...')\n",
    "\t\tself.stichSize = stichSize\n",
    "\t\tdirect = 'no_cuts_16b/'\n",
    "\t\tfiles = os.listdir(direct)\n",
    "\t\tf0 = np.load(direct+files[0])\n",
    "\t\tim0 = f0['arr_0']\n",
    "\t\tim_shape = im0.shape\n",
    "\t\tlab0 = f0['arr_1']\n",
    "\t\tlab_shape = (lab0.shape[0]-stichSize+1,lab0.shape[1]-stichSize+1,lab0.shape[2])\n",
    "\t\tself.N_channels = im_shape[2]\n",
    "\t\tself.N_out = lab_shape[2]\n",
    "\t\tself.images = np.zeros((len(files),)+im_shape,dtype=np.float32)\n",
    "\t\tself.labels = np.zeros((len(files),)+lab_shape,dtype=np.float32)\n",
    "\t\tfor i in range(len(files)):\n",
    "\t\t\ttemp = np.load(direct+files[i])\n",
    "\t\t\tself.images[i,:,:,:] = temp['arr_0']\n",
    "\t\t\tself.labels[i,:,:,:] = temp['arr_1'][(stichSize)//2:-(stichSize-1)//2,(stichSize)//2:-(stichSize-1)//2,:]\n",
    "\t\t\ttemp.close()\n",
    "\t\tprint('... files loaded. Analyzing data...')\n",
    "\t\tmaximu = np.zeros(self.N_channels)\n",
    "\t\tminimu = np.zeros(self.N_channels)\n",
    "\t\tfor i in range(self.N_channels):\n",
    "\t\t\tmaximu[i] = np.max(self.images[:,:,:,i])\n",
    "\t\t\tminimu[i] = np.min(self.images[:,:,:,i])\n",
    "\t\t\tself.images[:,:,:,i] -= minimu[i]\n",
    "\t\t\tself.images[:,:,:,i] /= (1.*maximu[i]-minimu[i])\n",
    "\t\t\n",
    "\t\tself.counter = np.zeros(self.N_out,dtype = np.int64)\n",
    "\t\tself.class_rate = np.zeros(self.N_out)\n",
    "\t\tself.testclass_rate = np.zeros(self.N_out)\n",
    "\t\tclasses = []\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tclasses += [np.array(np.where(self.labels[:,:,:,i]>0.1))]\n",
    "\t\tself.test_set_classes = []\n",
    "\t\tself.train_set_classes = []\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tclasses[i] = classes[i][:,np.random.permutation(classes[i].shape[1])]\n",
    "\t\t\tself.test_set_classes += [classes[i][:,:min(300,classes[i].shape[1])]]\n",
    "\t\t\tself.train_set_classes += [classes[i][:,min(300,classes[i].shape[1]):]]\n",
    "\t\t\tself.class_rate[i] = self.train_set_classes[i].shape[1]\n",
    "\t\t\tself.testclass_rate[i] = self.test_set_classes[i].shape[1]\n",
    "\t\t#should be a parameter between 0 and 1. 1: uniform over the '10' classes, 0: same rate as in whole set\n",
    "#\t\tprint(self.class_rate)\n",
    "\t\tself.uniformness = 0.98\n",
    "\t\n",
    "\tdef make_stiches(self,vec):\n",
    "\t\tmagicx = np.arange(self.stichSize)[np.newaxis,:,np.newaxis]\n",
    "\t\tmagicy = np.arange(self.stichSize)[np.newaxis,np.newaxis,:]\n",
    "\t\tresultLab = self.labels[vec[0],vec[1],vec[2],:]\n",
    "\t\tresultIm = self.images[vec[0,:,np.newaxis, np.newaxis],vec[1,:,np.newaxis,np.newaxis]+magicx,vec[2,:,np.newaxis,np.newaxis]+magicy, :]\n",
    "\t\trot = np.random.randint(4)\n",
    "\t\tflip = np.random.randint(2)\n",
    "\t\tif flip == 0:\n",
    "\t\t\tresultIm = np.flip(resultIm,1)\n",
    "\t\tresultIm = np.rot90(resultIm,rot,axes=(1,2))\n",
    "\t\treturn resultIm, resultLab[:,np.newaxis,np.newaxis,:]\n",
    "\t\t\n",
    "\tdef get_trainsamps_of_class(self, cl,amount):\n",
    "\t\tif amount > self.class_rate[cl]:\n",
    "\t\t\tprint( \"Error: not enough samples of class \" + str(cl))\n",
    "\t\tif(self.counter[cl] + amount >= self.class_rate[cl]):\n",
    "\t\t\tself.counter[cl] = 0\n",
    "\t\t\tself.train_set_classes[cl] = self.train_set_classes[cl][:,np.random.permutation(self.train_set_classes[cl].shape[1])]\n",
    "\t\tresult = self.train_set_classes[cl][:, self.counter[cl]:self.counter[cl]+amount]\n",
    "\t\tself.counter[cl] += amount\n",
    "\t\treturn result\n",
    "\t\t\n",
    "\tdef get_testsamps_of_class(self, cl,amount):\n",
    "\t\tif amount > self.testclass_rate[cl]:\n",
    "\t\t\tprint( \"Error: not enough samples of class \" + str(cl))\n",
    "\t\tresult = self.test_set_classes[cl][:, :amount]\n",
    "#\t\tprint(amount, result.shape)\n",
    "\t\treturn result\n",
    "\t\n",
    "\tdef get_random_points(self,n):\n",
    "\t\ttarget_shape = self.labels.shape\n",
    "\t\tresult = np.zeros((3,n))\n",
    "\t\tfor i in range(3):\n",
    "\t\t\tresult[i] = np.random.randint(target_shape[i],size=n)\n",
    "\t\treturn result\n",
    "\t\t\n",
    "\tdef getMiniBatch(self, miniBatchSize):\n",
    "\t\tclass_get = np.zeros(self.N_out,dtype = np.int64)\n",
    "\t\trates = (1./self.class_rate)**(1.-self.uniformness)\n",
    "\t\trates *= self.uniformness/np.sum(rates)\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tclass_get[i] = rand_round(rates[i]*miniBatchSize)\n",
    "\t\ts = np.sum(class_get)\n",
    "\t\tif s > miniBatchSize:\n",
    "\t\t\tclass_get[np.argmax(class_get)] -= s-miniBatchSize\n",
    "\t\tresultvec = np.zeros((3,miniBatchSize), dtype=np.intp)\n",
    "\t\tgot = 0\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tresultvec[:,got:got+class_get[i]] = self.get_trainsamps_of_class(i,class_get[i])\n",
    "\t\t\tgot += class_get[i]\n",
    "\t\tresultvec[:,got:] = self.get_random_points(miniBatchSize-got)\n",
    "\t\tresultvec = resultvec[:,np.random.permutation(miniBatchSize)]\n",
    "\t\treturn self.make_stiches(resultvec)\n",
    "\n",
    "\tdef getTestData(self,size=100, uniformness = -1):\n",
    "\t\tif uniformness == -1:\n",
    "\t\t\t\tuniformness = self.uniformness\n",
    "\t\tclass_get = np.zeros(self.N_out,dtype = np.int64)\n",
    "\t\trates = (1./self.testclass_rate)**(1.-uniformness)\n",
    "\t\trates *= uniformness/np.sum(rates)\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tclass_get[i] = rand_round(rates[i]*size)\n",
    "\t\ts = np.sum(class_get)\n",
    "\t\tif s > size:\n",
    "\t\t\tclass_get[np.argmax(class_get)] -= s-size\n",
    "\t\tresultvec = np.zeros((3,size), dtype=np.intp)\n",
    "\t\tgot = 0\n",
    "\t\tfor i in range(self.N_out):\n",
    "\t\t\tresultvec[:,got:got+class_get[i]] = self.get_testsamps_of_class(i,class_get[i])\n",
    "\t\t\tgot += class_get[i]\n",
    "\t\tresultvec[:,got:] = self.get_random_points(size-got)\t\n",
    "\t\treturn self.make_stiches(resultvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def Jacc(activations, truth, alpha=1e-4, beta=2.):\n",
    "    \"\"\"\n",
    "    computes the Jaccard index\n",
    "    activations: activation layer of the network (tensor)\n",
    "    truth: ground truth. Must have same shape as activations\n",
    "    \"\"\"\n",
    "    TPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*(1-truth),axis = 0),axis=0),axis=0)\n",
    "    FNc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum((1-activations)*truth,axis = 0),axis=0),axis=0)\n",
    "    return -tf.reduce_mean((TPc + alpha) / (TPc + FPc + FNc + beta))\n",
    "\n",
    "\n",
    "def logJacc(activations, truth, alpha=1e-4, beta=2.):\n",
    "    \"\"\"\n",
    "    computes the Jaccard index\n",
    "    activations: activation layer of the network (tensor)\n",
    "    truth: ground truth. Must have same shape as activations\n",
    "    \"\"\"\n",
    "    TPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*(1-truth),axis = 0),axis=0),axis=0)\n",
    "    FNc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum((1-activations)*truth,axis = 0),axis=0),axis=0)\n",
    "    return -tf.reduce_mean(tf.log((TPc + alpha + 1e-4) / (TPc + FPc + FNc + beta + 2.)))\n",
    "\n",
    "def individualJacc(activations, truth, alpha=1e-4, beta=2.):\n",
    "    \"\"\"\n",
    "    computes the Jaccard index\n",
    "    activations: activation layer of the network (tensor)\n",
    "    truth: ground truth. Must have same shape as activations\n",
    "    \"\"\"\n",
    "    TPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*truth,axis=0),axis=0),axis=0)\n",
    "    FPc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(activations*(1-truth),axis = 0),axis=0),axis=0)\n",
    "    FNc = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum((1-activations)*truth,axis = 0),axis=0),axis=0)\n",
    "    return (TPc + alpha + 1e-4) / (TPc + FPc + FNc + beta + 2.)\n",
    "\n",
    "\t\n",
    "def cross_entropy(activations, truth):\n",
    "    \"\"\"\n",
    "    computes the cross entropy\n",
    "    activations: activation layer of the network (tensor)\n",
    "    truth: ground truth. Must have same shape as activations\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = truth, logits = activations))\n",
    "\n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.6)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(-0.1, shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "\n",
    "class DSTLNet:\n",
    "\n",
    "    def __init__(self, convSize = 17, channels = 16, hiddenUnits = 100, hiddenUnits2 = 60 features = 10, activations = 'sigmoid', \n",
    "                 loss = 'logJacc', learningRate = 0.005, minimizer = 'adam', loadFile = ''):\n",
    "        \"\"\"\n",
    "        initialization of the net, setting all parameters. \n",
    "        convSize: size of the convolution patch (default:11)\n",
    "        channels: number of channels in image (default:8)\n",
    "        hiddenUnits: number of units in hidden layer (default:50)\n",
    "        features: number of output features (default: 10)\n",
    "        activations: type of activation function. Available functions: relu, sigmoid\n",
    "        loss: type of loss function. Available loss functions: logJacc, jacc, crossEntropy\n",
    "        loadFile: if not empty string, parameters will be loaded from specified file. Enter only filename without .ckpt as in DSTLNet.save(name) (default: empty string)\n",
    "        learningRate: the learning Rate to be used during training (default: 0.1)\n",
    "        optimizer: optimizer to be used during training (default: adam)\n",
    "        \"\"\"\n",
    "        self.conv_size = convSize\n",
    "        self.N_hidden = hiddenUnits\n",
    "        self.features = features\n",
    "        self.channels = channels\n",
    "        if loss == 'logJacc':\n",
    "            self.loss = logJacc\n",
    "        elif loss == 'crossEntropy':\n",
    "            self.loss == cross_entropy\n",
    "        elif loss == 'jacc':\n",
    "            self.loss = Jacc\n",
    "        else:\n",
    "            print('ERROR, loss function with name' + loss + ' not known. Please look at documentation')\n",
    "\n",
    "\n",
    "        def conv2d(xt,Wt):\n",
    "            \"\"\"\n",
    "            Wrapper for the tf conv2d function\n",
    "            \"\"\"\n",
    "            return tf.nn.conv2d(xt,Wt,strides=[1,1,1,1], padding='VALID')\n",
    "        \n",
    "        def conv2d_SAME(xt,Wt):\n",
    "            \"\"\"\n",
    "            Wrapper for the tf conv2d function\n",
    "            \"\"\"\n",
    "            return tf.nn.conv2d(xt,Wt,strides=[1,1,1,1], padding='SAME')\n",
    "        \n",
    "        ac_func = []\n",
    "        if activations == 'sigmoid':\n",
    "            ac_func = tf.nn.sigmoid\n",
    "        elif activations == 'relu':\n",
    "            ac_func = tf.nn.relu\n",
    "        else:\n",
    "            print('ERROR, activation function with name' + activations + ' not known. Please look at documentation')\n",
    "\n",
    "\n",
    "        self.truth = tf.placeholder(tf.float32, [None,None,None, features])\n",
    "        self.x_in = tf.placeholder(tf.float32, [None, None,None,channels])\n",
    "        #defining network\n",
    "    \n",
    "        '''\n",
    "        self.W_conv1 = weight_variable([convSize,convSize,channels,self.N_hidden],name='W_conv1')\n",
    "        self.b_conv1 = bias_variable([self.N_hidden],name='b_conv1')\n",
    "        self.conv_1 = ac_func(conv2d(self.x_in, self.W_conv1)+self.b_conv1)\n",
    "\n",
    "        self.W_conv2 = weight_variable([1,1,self.N_hidden,features], name='W_conv2')\n",
    "        self.b_conv2 = bias_variable([features],name='b_conv2')\n",
    "        self.out = tf.nn.sigmoid(conv2d(self.conv_1,self.W_conv2)+self.b_conv2)\n",
    "        '''\n",
    "        \n",
    "        filtSize2 = 1\n",
    "        \n",
    "        self.W_conv1 = weight_variable([convSize,convSize,channels,hiddenUnits2],name='W_conv1')\n",
    "        self.b_conv1 = bias_variable([hiddenUnits2],name='b_conv1')\n",
    "        conv_1 = tf.nn.sigmoid(conv2d(self.x_in, self.W_conv1)+self.b_conv1)\n",
    "        #conv_1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "        \n",
    "        \n",
    "        self.W_conv3 = weight_variable([filtSize2,filtSize2,hiddenUnits2,self.N_hidden],name='W_conv3')\n",
    "        self.b_conv3 = bias_variable([self.N_hidden],name='b_conv3')\n",
    "        conv_3 = tf.nn.sigmoid(conv2d_SAME(conv_1, self.W_conv3)+self.b_conv3)\n",
    "        \n",
    "\n",
    "        self.W_conv2 = weight_variable([1,1,self.N_hidden,features], name='W_conv2')\n",
    "        self.b_conv2 = bias_variable([features],name='b_conv2')\n",
    "        self.out = tf.nn.sigmoid(conv2d_SAME(conv_3,self.W_conv2)+self.b_conv2)\n",
    "        \n",
    "        \n",
    "        if minimizer == 'adam':\n",
    "            self.train_step = tf.train.AdamOptimizer(learningRate).minimize(self.loss(self.out, self.truth))\n",
    "        elif minimizer == 'gradientDescent':\n",
    "            self.train_step = tf.train.GradientDescentOptimizer(learningRate).minimize(self.loss(self.out, self.truth))\n",
    "        else:\n",
    "            print('ERROR: unknown minimizer')\n",
    "\n",
    "        #initializing variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.saver = tf.train.Saver()\n",
    "        if loadFile != '':\n",
    "            self.saver.restore(sess, \"/tmp/\"+loadFile+'.ckpt')\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, dataWrap, miniBatchSize = 50):\n",
    "        \"\"\"\n",
    "        trains the net\n",
    "        datWrap: A DataWrapper object\n",
    "        \"\"\"\n",
    "        batch = dataWrap.getMiniBatch(miniBatchSize)\n",
    "        \n",
    "    #       self.train_step = tf.train.AdamOptimizer(0.001).minimize(self.loss(self.out, self.truth))\n",
    "    #       sess.run(tf.global_variables_initializer())\n",
    "    #\t\ttest = dataWrap.getTestData(100)\n",
    "    #\t\tprint('Jaccard loss:', self.eval_loss(test[0],test[1]))\n",
    "        for i in range(int(50000/miniBatchSize)):\n",
    "            #print(sess.run(self.W_conv1)[0,0,:,0])\n",
    "            self.train_step.run(feed_dict={self.x_in: batch[0], self.truth: batch[1]})\n",
    "            #print(sess.run(self.W_conv1)[0,0,:,0])\n",
    "    #\t\tprint(sess.run(self.loss(self.out, self.truth), feed_dict={self.x_in: batch[0], self.truth: batch[1]}))\n",
    "            batch = dataWrap.getMiniBatch(miniBatchSize)\n",
    "    #\t\ttest = dataWrap.getTestData(100)\n",
    "    #\t\tprint('Jaccard loss:', self.eval_loss(test[0],test[1]))\n",
    "\n",
    "    def feedForward(self, data):\n",
    "        \"\"\"\n",
    "        computes predictions for data\n",
    "        data: image data of suitable shape\n",
    "        \"\"\"\n",
    "        return sess.run(self.out, feed_dict={self.x_in:data})\n",
    "\n",
    "    def eval_loss(self, data, truth, loss='iJacc'):\n",
    "        if loss == 'logJacc':\n",
    "            self.ev_loss = logJacc\n",
    "        elif loss == 'crossEntropy':\n",
    "            self.ev_loss == cross_entropy\n",
    "        elif loss == 'jacc':\n",
    "            self.ev_loss = Jacc\n",
    "        elif loss == 'iJacc':\n",
    "            self.ev_loss = individualJacc\n",
    "        elif self.ev_loss == None:\n",
    "            print('ERROR, loss function with name' + loss + ' not known. Please look at documentation')\n",
    "        return sess.run(self.ev_loss(self.out, self.truth), feed_dict={self.x_in : data, self.truth : truth})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save(self, name):\n",
    "        \"\"\"\n",
    "        saves model in /tmp/\n",
    "        name: name of the savefile without .ckpt\n",
    "        \"\"\"\n",
    "        save_path = self.saver.save(sess, \"/tmp/\"+name+\".ckpt\")\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "... files loaded. Analyzing data...\n"
     ]
    }
   ],
   "source": [
    "#import net\n",
    "#import DataWrapper2 as dw\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "dat = DataWrapper(stichSize=15)\n",
    "a,b = dat.getMiniBatch(100)\n",
    "\n",
    "mynet = DSTLNet(activations = 'sigmoid', minimizer = 'adam', learningRate = 0.0001, hiddenUnits = 120, convSize = 15)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(200):\n",
    "    mynet.train(dat, miniBatchSize = 100)\n",
    "    if i%5 == 0:\n",
    "        print \"step: \", i\n",
    "        print('uniformness:',dat.uniformness)\n",
    "        test = dat.getTestData(size=200)\n",
    "        jl = mynet.eval_loss(test[0],test[1])\n",
    "        print('Jaccard loss:', jl,  np.sum(jl)/10.)\n",
    "        dat.uniformness *= 0.97\n",
    "        print (time.time()- start)/60\n",
    "        start = time.time()\n",
    "        \n",
    "    #if i > 500:\n",
    "    #    dat.uniformness *= 0.95\n",
    "    \n",
    "\n",
    "mynet.save('mynet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0\n",
      "('uniformness:', 0.6689035031101793)\n",
      "('Jaccard loss:', array([ 0.33857068,  0.24641646,  0.59076297,  0.22712862,  0.45981938,\n",
      "        0.76626319,  0.65733105,  0.61059028,  0.42008361,  0.22593838], dtype=float32), 0.45429043769836425)\n",
      "2.9012057662\n",
      "Model saved in file: /tmp/mynet.ckpt\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(1):\n",
    "    mynet.train(dat, miniBatchSize = 100)\n",
    "    if i%5 == 0:\n",
    "        print \"step: \", i\n",
    "        print('uniformness:',dat.uniformness)\n",
    "        test = dat.getTestData(size=500)\n",
    "        jl = mynet.eval_loss(test[0],test[1])\n",
    "        print('Jaccard loss:', jl,  np.sum(jl)/10.)\n",
    "        dat.uniformness *= 0.97\n",
    "        print (time.time()- start)/60\n",
    "        start = time.time()\n",
    "        \n",
    "    #if i > 500:\n",
    "    #    dat.uniformness *= 0.95\n",
    "    \n",
    "\n",
    "mynet.save('mynet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0\n",
      "('uniformness:', 0.5981544892949797)\n",
      "('Jaccard loss:', array([ 0.36082187,  0.17760353,  0.54975832,  0.18423638,  0.5465458 ,\n",
      "        0.73744404,  0.68286264,  0.60582268,  0.39749211,  0.22865835], dtype=float32), 0.44712457656860349)\n",
      "2.90544921557\n",
      "step:  1\n",
      "('uniformness:', 0.5282900449453262)\n",
      "2.92024614811\n",
      "step:  2\n",
      "('uniformness:', 0.5071584431475131)\n",
      "3.03075243235\n",
      "step:  3\n",
      "('uniformness:', 0.4868721054216126)\n",
      "2.8851540486\n",
      "step:  4\n",
      "('uniformness:', 0.4673972212047481)\n",
      "2.86154824893\n",
      "step:  5\n",
      "('uniformness:', 0.4487013323565581)\n",
      "('Jaccard loss:', array([ 0.4005169 ,  0.17552578,  0.56981379,  0.2068374 ,  0.43521136,\n",
      "        0.70975876,  0.62838936,  0.58134389,  0.25242656,  0.20002258], dtype=float32), 0.4159846305847168)\n",
      "2.8587104996\n",
      "step:  6\n",
      "('uniformness:', 0.3962930167373121)\n",
      "2.85580553214\n",
      "step:  7\n",
      "('uniformness:', 0.3804412960678196)\n",
      "2.86528085073\n",
      "step:  8\n",
      "('uniformness:', 0.36522364422510684)\n",
      "2.90155651967\n",
      "step:  9\n",
      "('uniformness:', 0.35061469845610255)\n",
      "2.8629458348\n",
      "step:  10\n",
      "('uniformness:', 0.3365901105178584)\n",
      "('Jaccard loss:', array([ 0.41514105,  0.16172966,  0.59482771,  0.18854418,  0.46020746,\n",
      "        0.75322789,  0.67280585,  0.49563006,  0.30746895,  0.16685189], dtype=float32), 0.42164349555969238)\n",
      "2.86287904978\n",
      "step:  11\n",
      "('uniformness:', 0.29727638560937253)\n",
      "2.86576736768\n",
      "step:  12\n",
      "('uniformness:', 0.2853853301849976)\n",
      "2.86418553193\n",
      "step:  13\n",
      "('uniformness:', 0.2739699169775977)\n",
      "2.86307498217\n",
      "step:  14\n",
      "('uniformness:', 0.2630111202984938)\n",
      "2.86996276776\n",
      "step:  15\n",
      "('uniformness:', 0.252490675486554)\n",
      "('Jaccard loss:', array([ 0.37842605,  0.1572177 ,  0.47958773,  0.21180074,  0.44604406,\n",
      "        0.76650548,  0.70520979,  0.49196076,  0.21824487,  0.12542813], dtype=float32), 0.39804251194000245)\n",
      "2.87191176812\n",
      "step:  16\n",
      "('uniformness:', 0.2229997645897245)\n",
      "2.95330957969\n",
      "step:  17\n",
      "('uniformness:', 0.2140797740061355)\n",
      "2.90600666602\n",
      "step:  18\n",
      "('uniformness:', 0.20551658304589007)\n",
      "2.90007768472\n",
      "step:  19\n",
      "('uniformness:', 0.19729591972405447)\n",
      "2.94328614871\n",
      "step:  20\n",
      "('uniformness:', 0.18940408293509228)\n",
      "('Jaccard loss:', array([ 0.36768326,  0.12678508,  0.36483654,  0.16944003,  0.43314219,\n",
      "        0.73074454,  0.59519631,  0.40438348,  0.23768558,  0.09899941], dtype=float32), 0.35288965702056885)\n",
      "2.92868374983\n",
      "step:  21\n",
      "('uniformness:', 0.1672816860482735)\n",
      "2.93642296394\n",
      "step:  22\n",
      "('uniformness:', 0.16059041860634257)\n",
      "2.89677978357\n",
      "step:  23\n",
      "('uniformness:', 0.15416680186208886)\n",
      "2.89940390189\n",
      "step:  24\n",
      "('uniformness:', 0.1480001297876053)\n",
      "2.89646490018\n",
      "step:  25\n",
      "('uniformness:', 0.1420801245961011)\n",
      "('Jaccard loss:', array([ 0.3629967 ,  0.10097055,  0.47359717,  0.12121987,  0.42152599,\n",
      "        0.70306659,  0.58380115,  0.36908665,  0.21019842,  0.10546543], dtype=float32), 0.34519283771514891)\n",
      "2.89971061548\n",
      "step:  26\n",
      "('uniformness:', 0.12548516604327647)\n",
      "2.89482161601\n",
      "step:  27\n",
      "('uniformness:', 0.12046575940154541)\n",
      "2.89551953475\n",
      "step:  28\n",
      "('uniformness:', 0.11564712902548359)\n",
      "2.89443049828\n",
      "step:  29\n",
      "('uniformness:', 0.11102124386446424)\n",
      "2.89355358283\n",
      "step:  30\n",
      "('uniformness:', 0.10658039410988566)\n",
      "('Jaccard loss:', array([ 0.4351607 ,  0.14105533,  0.36960399,  0.10584766,  0.41983217,\n",
      "        0.72337371,  0.48030642,  0.207754  ,  0.18980256,  0.09105872], dtype=float32), 0.31637954711914062)\n",
      "2.89986088276\n",
      "step:  31\n",
      "('uniformness:', 0.09413180407785102)\n",
      "2.89596199989\n",
      "step:  32\n",
      "('uniformness:', 0.09036653191473697)\n",
      "2.90417038202\n",
      "step:  33\n",
      "('uniformness:', 0.08675187063814749)\n",
      "2.89624048471\n",
      "step:  34\n",
      "('uniformness:', 0.08328179581262159)\n",
      "2.90374825001\n",
      "step:  35\n",
      "('uniformness:', 0.07995052398011672)\n",
      "('Jaccard loss:', array([ 0.44509417,  0.06450959,  0.29724884,  0.10058104,  0.44685912,\n",
      "        0.71387345,  0.49094737,  0.28097102,  0.16026407,  0.05461945], dtype=float32), 0.30549681186676025)\n",
      "2.89918739796\n",
      "step:  36\n",
      "('uniformness:', 0.07061230277923908)\n",
      "2.89413104852\n",
      "step:  37\n",
      "('uniformness:', 0.0677878106680695)\n",
      "2.90001716614\n",
      "step:  38\n",
      "('uniformness:', 0.06507629824134673)\n",
      "2.89634644985\n",
      "step:  39\n",
      "('uniformness:', 0.062473246311692855)\n",
      "2.88525919914\n",
      "step:  40\n",
      "('uniformness:', 0.05997431645922514)\n",
      "('Jaccard loss:', array([ 0.41091064,  0.13027285,  0.20792688,  0.11221576,  0.46851984,\n",
      "        0.7215572 ,  0.36538655,  0.2773011 ,  0.17942162,  0.04673744], dtype=float32), 0.2920249938964844)\n",
      "2.89318048159\n",
      "step:  41\n",
      "('uniformness:', 0.05296931629678764)\n",
      "2.88807394902\n",
      "step:  42\n",
      "('uniformness:', 0.05085054364491613)\n",
      "2.88930598497\n",
      "step:  43\n",
      "('uniformness:', 0.04881652189911948)\n",
      "2.87552053531\n",
      "step:  44\n",
      "('uniformness:', 0.0468638610231547)\n",
      "2.8580121994\n",
      "step:  45\n",
      "('uniformness:', 0.04498930658222851)\n",
      "('Jaccard loss:', array([ 0.38923028,  0.16988042,  0.26367298,  0.13910003,  0.45837623,\n",
      "        0.72237176,  0.35753423,  0.33531171,  0.05971821,  0.01599082], dtype=float32), 0.29111864566802981)\n",
      "2.85784363349\n",
      "step:  46\n",
      "('uniformness:', 0.039734555573424216)\n",
      "2.85135628382\n",
      "step:  47\n",
      "('uniformness:', 0.03814517335048725)\n",
      "2.8527564168\n",
      "step:  48\n",
      "('uniformness:', 0.03661936641646776)\n",
      "2.85359683037\n",
      "step:  49\n",
      "('uniformness:', 0.03515459175980905)\n",
      "2.85733391444\n",
      "step:  50\n",
      "('uniformness:', 0.03374840808941668)\n",
      "('Jaccard loss:', array([ 0.42566308,  0.07436293,  0.10621227,  0.0895698 ,  0.47974211,\n",
      "        0.77333373,  0.14649802,  0.30860287,  0.0646324 ,  0.02142994], dtype=float32), 0.24900472164154053)\n",
      "2.85880045096\n",
      "step:  51\n",
      "('uniformness:', 0.029806594024572815)\n",
      "2.85730181932\n",
      "step:  52\n",
      "('uniformness:', 0.0286143302635899)\n",
      "2.85445270141\n",
      "step:  53\n",
      "('uniformness:', 0.027469757053046304)\n",
      "2.85312833389\n",
      "step:  54\n",
      "('uniformness:', 0.026370966770924452)\n",
      "2.85386530161\n",
      "step:  55\n",
      "('uniformness:', 0.025316128100087473)\n",
      "('Jaccard loss:', array([ 0.3785395 ,  0.11692081,  0.24383748,  0.09548718,  0.4161931 ,\n",
      "        0.71622199,  0.45176718,  0.13577142,  0.08670639,  0.05707013], dtype=float32), 0.26985149383544921)\n",
      "3.1106449008\n",
      "step:  56\n",
      "('uniformness:', 0.022359204337997256)\n",
      "3.21061813434\n",
      "step:  57\n",
      "('uniformness:', 0.021464836164477363)\n",
      "2.93466778199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b78bb71fd94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmynet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatchSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniformness\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8e351dcce6af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataWrap, miniBatchSize)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mminiBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m#print(sess.run(self.W_conv1)[0,0,:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;31m#print(sess.run(self.W_conv1)[0,0,:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m#                   print(sess.run(self.loss(self.out, self.truth), feed_dict={self.x_in: batch[0], self.truth: batch[1]}))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \"\"\"\n\u001b[0;32m-> 1588\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3830\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3832\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "for i in range(100):\n",
    "    mynet.train(dat, miniBatchSize = 100)\n",
    "    dat.uniformness *= 0.96\n",
    "\n",
    "    print \"step: \", i\n",
    "    print('uniformness:',dat.uniformness)\n",
    "    if i%5 == 0:\n",
    "        \n",
    "        test = dat.getTestData(size=500)\n",
    "        jl = mynet.eval_loss(test[0],test[1])\n",
    "        print('Jaccard loss:', jl,  np.sum(jl)/10.)\n",
    "        dat.uniformness *= 0.92\n",
    "    print (time.time()- start)/60\n",
    "    start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print maximu, minimu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
